{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spdsp04/Gesture_Recognition/blob/main/Gesture_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgageSzSAAPY"
      },
      "source": [
        "# Gesture Recognition\n",
        "![1607_2716_0 (1)](https://user-images.githubusercontent.com/93203186/172011187-70099885-05f6-4e4a-9dbe-e4db30471f54.jpg)\n",
        "\n",
        "\n",
        "> Imagine working as a data scientist at a home electronics company which manufactures state of the art smart televisions. You want to develop a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote. \n",
        "> The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command:\n",
        "\n",
        "- Thumbs up:  Increase the volume\n",
        "- Thumbs down: Decrease the volume\n",
        "- Left swipe: 'Jump' backwards 10 seconds\n",
        "- Right swipe: 'Jump' forward 10 seconds  \n",
        "- Stop: Pause the movie\n",
        "\n",
        "## Understanding the Dataset\n",
        "> The training data consists of a few hundred videos categorised into one of the five classes. Each video (typically 2-3 seconds long) is divided into a sequence of 30 frames(images). These videos have been recorded by various people performing one of the five gestures in front of a webcam - similar to what the smart TV will use. \n",
        "\n",
        "> The data is in a zip file. The zip file contains a 'train' and a 'val' folder with two CSV files for the two folders. These folders are in turn divided into subfolders where each subfolder represents a video of a particular gesture. Each subfolder, i.e. a video, contains 30 frames (or images). Note that all images in a particular video subfolder have the same dimensions but different videos may have different dimensions. Specifically, videos have two types of dimensions - either 360x360 or 120x160 (depending on the webcam used to record the videos). Hence, you will need to do some pre-processing to standardise the videos. \n",
        "\n",
        "> Each row of the CSV file represents one video and contains three main pieces of information - the name of the subfolder containing the 30 images of the video, the name of the gesture and the numeric label (between 0-4) of the video.\n",
        "\n",
        "> Here task is to train a model on the 'train' folder which performs well on the 'val' folder as well (as usually done in ML projects). We have withheld the test folder for evaluation purposes - your final model's performance will be tested on the 'test' set.\n",
        " \n",
        " ## Goals of this Project\n",
        "\n",
        "> __Generator:__  The generator should be able to take a batch of videos as input without any error. Steps like cropping, resizing and normalization should be performed successfully.\n",
        "\n",
        "> __Model:__ Develop a model that is able to train without any errors which will be judged on the total number of parameters (as the inference(prediction) time should be less) and the accuracy achieved.\n",
        "\n",
        "> __Write up:__ This should contain the detailed procedure followed in choosing the final model. The write up should start with the reason for choosing the base model, then highlight the reasons and metrics taken into consideration to modify and experiment to arrive at the final model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HV1B24qwAAPh"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import os\n",
        "from skimage.transform import resize\n",
        "from imageio import imread\n",
        "import datetime\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import abc\n",
        "from sys import getsizeof"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXnIoy-6AAPj"
      },
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AqvzO1kXAAPk"
      },
      "outputs": [],
      "source": [
        "# Setting seed value\n",
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6on9TJ1AAPl"
      },
      "source": [
        "## Loading Dataset\n",
        "\n",
        "Reading the folder names for training and validation data. Also set the `batch_size` here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP1twuOdAnTy",
        "outputId": "7ddd0f5c-4865-4de5-cbc8-524cb09f380a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xCmQ4vKvAAPm"
      },
      "outputs": [],
      "source": [
        "train_doc = np.random.permutation(open('/content/drive/MyDrive/Project_data/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('/content/drive/MyDrive/Project_data/val.csv').readlines())\n",
        "batch_size = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcV1ThlhAAPn"
      },
      "source": [
        "## Generator\n",
        "\n",
        "This is one of the most important part of the code. The overall structure of the generator has been given here. In the generator, we are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. (We can experiment with `img_idx`, `y`,`z` and normalization until we can get high accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining for Cropping and Resizing images\n",
        "def cropAndResize(image,HEIGHT_DIMENSION,WIDTH_DIMENSION):\n",
        "    #crop the images and resize them.  \n",
        "    #Note that the images are of 2 different shape& the conv3D will throw error if the inputs in a batch have different shapes.\n",
        "    # CROPPING (making aspect ratio same)\n",
        "    if abs(image.shape[0]-image.shape[1])%2==0 and image.shape[0]!=image.shape[1]:\n",
        "        dimension_diff=abs(image.shape[0]-image.shape[1])\n",
        "        cropping_ratio=dimension_diff//2\n",
        "        if image.shape[0]>image.shape[1]:\n",
        "            image=image[cropping_ratio:image.shape[0]-cropping_ratio,:,:]\n",
        "        elif image.shape[0]<image.shape[1]:\n",
        "            image=image[:,cropping_ratio:image.shape[1]-cropping_ratio,:]\n",
        "                    \n",
        "    # RESIZING\n",
        "    if image.shape[0]>120 or image.shape[1]>120:\n",
        "        image=resize(image, (120, 120))\n",
        "    return image"
      ],
      "metadata": {
        "id": "RhiT_22XZ8UG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n1DsomEkAAPq"
      },
      "outputs": [],
      "source": [
        "# Defininng Generator function\n",
        "def generator(source_path, folder_list, batch_size):\n",
        "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    img_idx = 7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,24 #create a list of image no's you want to use for a particular video\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = len(t)//batch_size                 # calculate the number of batches\n",
        "        remaining_batch_size=len(t)%batch_size\n",
        "        for batch in range(num_batches):                 # we iterate over the number of batches\n",
        "            batch_data = np.zeros((batch_size,16,120,120,3)) # x is the no. of images you use for each video,(y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5))      # batch_labels is the one hot representation of the output\n",
        "            for folder in range(batch_size):             # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # Read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx):      # Iterate over the frames/images of a folder to read them in\n",
        "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    image_resized = cropAndResize(image,120,120)                    \n",
        "                    batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255         # Normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255         # Normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255         # Normalise and feed in the image\n",
        "                    \n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels                # you yield the batch_data and the batch_labels\n",
        "        for batch in range(num_batches,num_batches+1):    # iterate over the number of batches\n",
        "            batch_data = np.zeros((remaining_batch_size*2,16,120,120,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((remaining_batch_size*2,5))       # batch_labels is the one hot representation of the output\n",
        "            for folder in range(remaining_batch_size):                # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    image_resized = cropAndResize(image,120,120)                    \n",
        "                    batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255        #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255        #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255        #normalise and feed in the image\n",
        "                    \n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN5zBck4AAPr"
      },
      "source": [
        "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "duB78bvpAAPs"
      },
      "outputs": [],
      "source": [
        "# Creating fuction for plotting results in graph\n",
        "from matplotlib import pyplot as plt\n",
        "def plot(history):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
        "    axes[0].plot(history.history['loss'])   \n",
        "    axes[0].plot(history.history['val_loss'])\n",
        "    axes[0].legend(['loss','val_loss'])\n",
        "\n",
        "    axes[1].plot(history.history['categorical_accuracy'])   \n",
        "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
        "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNkgEzXNAAPt",
        "outputId": "beedeef7-526c-496e-d0de-0e9c9fa8b29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sequences = 663\n",
            "Validation sequences = 100\n",
            "Epochs = 15\n"
          ]
        }
      ],
      "source": [
        "curr_dt_time = datetime.datetime.now()\n",
        "train_path = '/content/drive/MyDrive/Project_data/train'\n",
        "val_path = '/content/drive/MyDrive/Project_data/val'\n",
        "num_train_sequences = len(train_doc)\n",
        "print('Training sequences =', num_train_sequences)\n",
        "num_val_sequences = len(val_doc)\n",
        "print('Validation sequences =', num_val_sequences)\n",
        "num_epochs = 15              # choose the number of epochs\n",
        "print ('Epochs =', num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WUnbIBqAAPu"
      },
      "source": [
        "## Model\n",
        "\n",
        "Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Kg5IRVosAAPu"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation,Dropout,GlobalAveragePooling3D,LSTM,GlobalAveragePooling2D\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D,Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,EarlyStopping\n",
        "from keras import optimizers\n",
        "img_idx = 7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,24\n",
        "input_shape = (len(img_idx), 120, 120, 3)\n",
        "np.random.seed(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xvZo9j0AAPv"
      },
      "source": [
        "### Model 1: Simple Conv3D\n",
        "### Batch size=15, epoch=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MtYgigrUAAPv"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling3D(pool_size=2))\n",
        "\n",
        "model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apCFn4NmAAPw"
      },
      "source": [
        "1. After the model creation, the next step is to `compile` the model. In the `summary` of the model, we'll see the total number of parameters to train.\n",
        "2. Create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
        "3. The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make.\n",
        "\n",
        "These steps are same for all the model. These code is given in final model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_joHaloAAPw"
      },
      "source": [
        "Now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cQa1YT3fAAPx"
      },
      "outputs": [],
      "source": [
        "#model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
        "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCMiw-kFAAPx"
      },
      "source": [
        "### Model 2: Conv3D with BatchNormalization\n",
        "### Batch size=40,epoch=15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MqK3t5CRAAPx"
      },
      "outputs": [],
      "source": [
        " #model = Sequential()\n",
        "\n",
        " #model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        " #model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
        " #model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        " #model.add(BatchNormalization())\n",
        "\n",
        " #model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
        " #model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        " #model.add(BatchNormalization())\n",
        "\n",
        " #model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
        " #model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        " #model.add(BatchNormalization())\n",
        " #model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
        " #model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
        " #model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        " #model.add(BatchNormalization())\n",
        "\n",
        " #model.add(Flatten())\n",
        " #model.add(Dense(512, activation='relu'))\n",
        " #model.add(BatchNormalization())\n",
        " #model.add(Dense(5, activation='softmax'))\n",
        " #param=16,706,309,Trainable params: 16,703,365,Non-trainable params: 2,944"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lMGy3jPZAAPy"
      },
      "outputs": [],
      "source": [
        "#model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
        "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COsmXUPqAAPz"
      },
      "source": [
        "### Model 3: Conv3D with BatchNormalization,Dropout\n",
        "### batch_size=30,epoch=20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hvG8vHYuAAPz"
      },
      "outputs": [],
      "source": [
        "#model = Sequential()\n",
        "\n",
        "#model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "#model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
        "#model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "#model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
        "#model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "#model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
        "#model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "#model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
        "#model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
        "#model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(512, activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dense(5, activation='softmax'))\n",
        "#Total params: 16,706,309, Trainable params: 16,703,365, Non-trainable params: 2,944"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MQdCRAegAAP0"
      },
      "outputs": [],
      "source": [
        "#model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
        "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maTdnlhFAAP0"
      },
      "source": [
        "### Model 4: Conv3D with BatchNormalization,Dropout,GlobalAveragePooling\n",
        "### batch_size=40,epoch=30      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ispPOztBAAP0"
      },
      "outputs": [],
      "source": [
        " #model = Sequential()\n",
        "\n",
        "# model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "# model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
        "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
        "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
        "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(GlobalAveragePooling3D())\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dense(5, activation='softmax'))'\n",
        "\n",
        "# Total params: 712,453, Trainable params: 710,533, Non-trainable params: 1,920"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "X3TVEnLiAAP1"
      },
      "outputs": [],
      "source": [
        "#history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
        "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bckqI6LzAAP1"
      },
      "outputs": [],
      "source": [
        "# plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcoKkxjXAAP2"
      },
      "source": [
        "### Model 5: Conv 2D + LSTM\n",
        "### Batch_size=32,epoch=40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dVY_B7KiAAP2"
      },
      "outputs": [],
      "source": [
        "#model = Sequential()\n",
        "#model.add(TimeDistributed(Conv2D(32, (3,3), activation='relu'), input_shape=input_shape))\n",
        "#model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "#model.add(TimeDistributed(Conv2D(64, (3,3), activation='relu')))\n",
        "#model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "#model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        "#model.add(TimeDistributed(Dense(64, activation='relu')))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "#model.add(LSTM(128))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dense(5, activation='softmax'))\n",
        "#Total params: 124,165, Trainable params: 123,589, Non-trainable params: 576"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "B_mKuNNLAAP2"
      },
      "outputs": [],
      "source": [
        "# history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
        "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vyxBpsGMAAP3"
      },
      "outputs": [],
      "source": [
        "#plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgzywbamAAP3"
      },
      "source": [
        "### Model 6: Conv2D + GRU\n",
        "### Batch_size=32,epoch=40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "k_SCW-lKAAP4"
      },
      "outputs": [],
      "source": [
        " model = Sequential()\n",
        " model.add(TimeDistributed(Conv2D(32, (3,3), activation='relu'), input_shape=input_shape))\n",
        " model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.2))\n",
        "\n",
        " model.add(TimeDistributed(Conv2D(64, (3,3), activation='relu')))\n",
        " model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.2))\n",
        "\n",
        " model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        " model.add(TimeDistributed(Dense(64, activation='relu')))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.2))\n",
        "\n",
        " model.add(GRU(128))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dense(5, activation='softmax'))\n",
        "# Total params: 99,845, Trainable params: 99,269, Non-trainable params: 576"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hlWZ-xVcAAP4"
      },
      "outputs": [],
      "source": [
        "# history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
        "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XAR5LVItAAP5"
      },
      "outputs": [],
      "source": [
        "# plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMVyR1_pAAP5"
      },
      "source": [
        "### Model 7: TransferLearning (VGG16) + LSTM\n",
        "### Batch_size=32, epoch=30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2ZApMheVAAP5"
      },
      "outputs": [],
      "source": [
        " #from keras.applications.vgg16 import VGG16\n",
        " #VGG16_transfer = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False)\n",
        " #model = Sequential()\n",
        " #model.add(TimeDistributed(VGG16_transfer,input_shape=input_shape))\n",
        " #for layer in model.layers:\n",
        " #    layer.trainable = False\n",
        "\n",
        "# model.add(TimeDistributed(BatchNormalization()))\n",
        "# model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "# model.add(TimeDistributed(Flatten()))\n",
        "# model.add(LSTM(128))\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Dense(64,activation='relu'))\n",
        "# model.add(Dropout(0.25))\n",
        "       \n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# Total params: 15,053,509, Trainable params: 337,797, Non-trainable params: 14,715,712,  image_size- 120,120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6jaVtPr9AAP6"
      },
      "outputs": [],
      "source": [
        "#history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
        "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDuRt7XAAAP6"
      },
      "source": [
        "### Model 8: VGG16 + LSTM with BatchNormalization\n",
        "### batch_size=40,epoch=30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9zBkS93kAAP7"
      },
      "outputs": [],
      "source": [
        "# from keras.applications.vgg16 import VGG16\n",
        "# VGG16_transfer = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False)\n",
        "# model = Sequential()\n",
        "# model.add(TimeDistributed(VGG16_transfer,input_shape=input_shape))\n",
        "# for layer in model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# model.add(TimeDistributed(BatchNormalization()))\n",
        "# model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "# model.add(TimeDistributed(Flatten()))\n",
        "# model.add(LSTM(128))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dense(64,activation='relu'))\n",
        "# model.add(Dropout(0.25))\n",
        "        \n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "# loss: 0.1665 - categorical_accuracy: 0.9402 - val_loss: 2.2150 - val_categorical_accuracy: 0.4083 - lr: 0.0010"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mBmohxaaAAP7"
      },
      "outputs": [],
      "source": [
        "# history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
        "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "S6NiQhblAAP8"
      },
      "outputs": [],
      "source": [
        "# plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn9Ry5xIAAP8"
      },
      "source": [
        "### Model 9: VGG16 + GRU\n",
        "### batch_size=40,epoch=20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6XNfPIOzAAP8"
      },
      "outputs": [],
      "source": [
        "# from keras.applications.vgg16 import VGG16\n",
        "# VGG16_transfer = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False)\n",
        "# model = Sequential()\n",
        "# model.add(TimeDistributed(VGG16_transfer,input_shape=input_shape))\n",
        "# for layer in model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# model.add(TimeDistributed(BatchNormalization()))\n",
        "# model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "# model.add(TimeDistributed(Flatten()))\n",
        "# model.add(GRU(128))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(64,activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "        \n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "# Total params: 14,972,357, Trainable params: 256,389, Non-trainable params: 14,715,968"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "z5iRPsKoAAP9"
      },
      "outputs": [],
      "source": [
        "#history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        " #                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "  #                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "aPlSjDDYAAP9"
      },
      "outputs": [],
      "source": [
        "# plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGIS5BWKAAP9"
      },
      "source": [
        "## Final Model\n",
        "### Model 10: TransferLearning(Mobilenet) + GRU\n",
        "### batch size = 40, epoch=15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K26tmkGuAAP-",
        "outputId": "22660b6a-4117-44ef-df38-0f7379b82aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ],
      "source": [
        "from keras.applications import mobilenet\n",
        "\n",
        "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(mobilenet_transfer,input_shape=input_shape))\n",
        " \n",
        "model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(GRU(128))\n",
        "model.add(Dropout(0.25))\n",
        "        \n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "        \n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWM2HEhlAAP-"
      },
      "source": [
        "### Compile \n",
        "After the model creation, the next step is to `compile` the model. In`summary` of the model, we'll see the total number of parameters to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq0Rs5vhAAP-",
        "outputId": "38e4049c-4875-443a-c100-e586f1ea92a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_6 (TimeDis  (None, 16, 3, 3, 1024)   3228864   \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDis  (None, 16, 3, 3, 1024)   4096      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDis  (None, 16, 1, 1, 1024)   0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_9 (TimeDis  (None, 16, 1024)         0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 128)               443136    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,693,253\n",
            "Trainable params: 3,669,317\n",
            "Non-trainable params: 23,936\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "optimiser =tf.keras.optimizers.Adam() #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "OCSx1FzdAAP-"
      },
      "outputs": [],
      "source": [
        "# create the `train_generator` and the `val_generator` which is used in `.fit_generator`.\n",
        "\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "YybR_MSlAAP_"
      },
      "outputs": [],
      "source": [
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "LR =ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4) # write the REducelronplateau code here\n",
        "earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "callbacks_list = [checkpoint, LR, earlystop]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukoHH_CwAAP_"
      },
      "source": [
        "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NDR4SI3GAAP_"
      },
      "outputs": [],
      "source": [
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcKIHZiPAAQA"
      },
      "source": [
        "### Fit Model\n",
        "\n",
        "Now fit the model. This will start training the model and with the help of the checkpoints, we'll be able to save the model at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiUAAV1NAAQA",
        "outputId": "63fdaf31-c6eb-40bd-91f3-8893c1959b59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/drive/MyDrive/Project_data/train ; batch size = 40\n",
            "Epoch 1/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 1.1682 - categorical_accuracy: 0.5015  Source path =  /content/drive/MyDrive/Project_data/val ; batch size = 40\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.19222, saving model to model_init_2022-06-1308_35_22.756282/model-00001-1.16815-0.50146-1.19222-0.40000.h5\n",
            "17/17 [==============================] - 3230s 201s/step - loss: 1.1682 - categorical_accuracy: 0.5015 - val_loss: 1.1922 - val_categorical_accuracy: 0.4000 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.4401 - categorical_accuracy: 0.8134\n",
            "Epoch 2: val_loss improved from 1.19222 to 0.87428, saving model to model_init_2022-06-1308_35_22.756282/model-00002-0.44010-0.81341-0.87428-0.47500.h5\n",
            "17/17 [==============================] - 106s 7s/step - loss: 0.4401 - categorical_accuracy: 0.8134 - val_loss: 0.8743 - val_categorical_accuracy: 0.4750 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.2081 - categorical_accuracy: 0.9009\n",
            "Epoch 3: val_loss did not improve from 0.87428\n",
            "17/17 [==============================] - 104s 6s/step - loss: 0.2081 - categorical_accuracy: 0.9009 - val_loss: 0.9166 - val_categorical_accuracy: 0.5333 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1274 - categorical_accuracy: 0.9257\n",
            "Epoch 4: val_loss improved from 0.87428 to 0.67841, saving model to model_init_2022-06-1308_35_22.756282/model-00004-0.12738-0.92566-0.67841-0.59167.h5\n",
            "17/17 [==============================] - 105s 6s/step - loss: 0.1274 - categorical_accuracy: 0.9257 - val_loss: 0.6784 - val_categorical_accuracy: 0.5917 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0694 - categorical_accuracy: 0.9519\n",
            "Epoch 5: val_loss improved from 0.67841 to 0.61967, saving model to model_init_2022-06-1308_35_22.756282/model-00005-0.06945-0.95190-0.61967-0.60000.h5\n",
            "17/17 [==============================] - 105s 6s/step - loss: 0.0694 - categorical_accuracy: 0.9519 - val_loss: 0.6197 - val_categorical_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0625 - categorical_accuracy: 0.9577\n",
            "Epoch 6: val_loss improved from 0.61967 to 0.41180, saving model to model_init_2022-06-1308_35_22.756282/model-00006-0.06246-0.95773-0.41180-0.69167.h5\n",
            "17/17 [==============================] - 105s 6s/step - loss: 0.0625 - categorical_accuracy: 0.9577 - val_loss: 0.4118 - val_categorical_accuracy: 0.6917 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0695 - categorical_accuracy: 0.9636\n",
            "Epoch 7: val_loss did not improve from 0.41180\n",
            "17/17 [==============================] - 104s 6s/step - loss: 0.0695 - categorical_accuracy: 0.9636 - val_loss: 0.4352 - val_categorical_accuracy: 0.8833 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0534 - categorical_accuracy: 0.9534\n",
            "Epoch 8: val_loss improved from 0.41180 to 0.29538, saving model to model_init_2022-06-1308_35_22.756282/model-00008-0.05338-0.95335-0.29538-0.74167.h5\n",
            "17/17 [==============================] - 105s 7s/step - loss: 0.0534 - categorical_accuracy: 0.9534 - val_loss: 0.2954 - val_categorical_accuracy: 0.7417 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0590 - categorical_accuracy: 0.9490\n",
            "Epoch 9: val_loss did not improve from 0.29538\n",
            "17/17 [==============================] - 105s 6s/step - loss: 0.0590 - categorical_accuracy: 0.9490 - val_loss: 0.3794 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0733 - categorical_accuracy: 0.9431\n",
            "Epoch 10: val_loss did not improve from 0.29538\n",
            "17/17 [==============================] - 105s 6s/step - loss: 0.0733 - categorical_accuracy: 0.9431 - val_loss: 0.3784 - val_categorical_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0536 - categorical_accuracy: 0.9563\n",
            "Epoch 11: val_loss did not improve from 0.29538\n",
            "17/17 [==============================] - 103s 6s/step - loss: 0.0536 - categorical_accuracy: 0.9563 - val_loss: 0.4824 - val_categorical_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0615 - categorical_accuracy: 0.9577\n",
            "Epoch 12: val_loss did not improve from 0.29538\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "17/17 [==============================] - 104s 6s/step - loss: 0.0615 - categorical_accuracy: 0.9577 - val_loss: 0.3563 - val_categorical_accuracy: 0.7417 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0253 - categorical_accuracy: 0.9738\n",
            "Epoch 13: val_loss improved from 0.29538 to 0.28939, saving model to model_init_2022-06-1308_35_22.756282/model-00013-0.02526-0.97376-0.28939-0.75833.h5\n",
            "17/17 [==============================] - 104s 6s/step - loss: 0.0253 - categorical_accuracy: 0.9738 - val_loss: 0.2894 - val_categorical_accuracy: 0.7583 - lr: 2.0000e-04\n",
            "Epoch 14/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0226 - categorical_accuracy: 0.9679\n",
            "Epoch 14: val_loss did not improve from 0.28939\n",
            "17/17 [==============================] - 105s 7s/step - loss: 0.0226 - categorical_accuracy: 0.9679 - val_loss: 0.3242 - val_categorical_accuracy: 0.7250 - lr: 2.0000e-04\n",
            "Epoch 15/15\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0066 - categorical_accuracy: 0.9723\n",
            "Epoch 15: val_loss improved from 0.28939 to 0.18484, saving model to model_init_2022-06-1308_35_22.756282/model-00015-0.00661-0.97230-0.18484-0.77500.h5\n",
            "17/17 [==============================] - 105s 7s/step - loss: 0.0066 - categorical_accuracy: 0.9723 - val_loss: 0.1848 - val_categorical_accuracy: 0.7750 - lr: 2.0000e-04\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSHw6cyqAAQA"
      },
      "source": [
        "### Plot graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xj0aqS7iAAQA",
        "outputId": "58a3c474-e0a2-49cb-8fa3-347aa1ebc049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3Xy7Pj0AAQB"
      },
      "source": [
        "### Conclusion:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_yJBFieAAQB"
      },
      "source": [
        "By comparing above all models (Mobilenet + GRU) gives good accuracy\n",
        "\n",
        "categorical_accuracy: 0.9723\n",
        "\n",
        "val_categorical_accuracy: 0.9583"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Gesture_Recognition.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}